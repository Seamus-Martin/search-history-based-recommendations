**Description**

AI powered browsing history analyzer with shopping assitant, using FastAPI, SQLAlchemy, and OpenAI API. The system uses a chrome extension to capture visited pages, extract meaning and summarize with an AI agent, and stores results in a database. A conversational assistant can assist by providing insight into your shopping habits and suggest stores based on a given dataset of shopify stores.

**Setup**

Install Chrome Extension (requires Chrome):
1. Download history-capture-extension
2. Navigate to "load unpacked" in chrome extension manager (chrome://extensions), select history-capture-extension
3. Ensure the option for read and change data is enabled

Install the search-history-backend (requires python):
1. Download search-history-backend, go to its directory in terminal
2. set up virtual environment:
python3 -m venv venv
source venv/bin/activate (mac) or venv\Scripts\activate (windows)
3. Install dependencies:
pip install -r requirements.txt
4. Create and OpenAI api key, and attach using:
export OPENAI_API_KEY="sk-..."
5. Start server:
uvicorn main:app --reload --port 8000
6. view the UI at:
http://localhost:8000/ui

Note: to delete all existing searches: rm history.db



**Design Decisions/Tradeoffs**
1. 
I decided to structure the user data storage as follows:

for each site visited, the following information is stored:
    - a title
    - the URL
    - a summary containing the important context of the site generated by analysis_agent

I decided to use this structure to store the user data this way because it allows me to remove certain parts of the context easily by removing entries that I don't want. 

What I would do in the future: 

I would have a user data structure that has elements that include things like price range, interests, etc. analysis_agent would update this structure, adding missing context. This will be more scalable when users have large numbers of stored searches.

2. 
As the problem suggested, I scraped a number of shopify stores and extracted a summary of their products, prices, etc. This works well for the demo but an improvement would be adding search capabilities so that the program can find relevant results from the internet, giving more relevant and up to date information. Will also improve the performance when more than the ~100 stores are being searched.